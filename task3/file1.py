import os
import streamlit as st
from groq import Groq
from dotenv import load_dotenv

# 1. Setup
load_dotenv()
client = Groq(api_key=os.getenv("GROQ_API_KEY"))

st.title("Groq Chatbot")

# 2. Initialize Memory (Session State)
if "messages" not in st.session_state:
    st.session_state.messages = [] #A "sticky" dictionary that survives reruns. We store all past messages in a list called messages.

# 3. Display History
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# 4. Chat Logic
if prompt := st.chat_input("Say something..."):
    # Show user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generate & Stream AI response
    try:
        with st.chat_message("assistant"):
            response_stream = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=st.session_state.messages,
                stream=True,
            )
            # This helper streams the text to the UI
            full_response = st.write_stream(
                chunk.choices[0].delta.content 
                for chunk in response_stream 
                if chunk.choices[0].delta.content #delta.content is for small deliveries of words from text. eg ["Hi", "I", "am", "good"] instead of message.content which gives "Hi i am good".
            )

# choices is a list (array) of possible responses generated by the AI for your single prompt.
# Because it is a list, we use [0] to grab the first item in that list.

        st.session_state.messages.append({"role": "assistant", "content": full_response})
    except Exception as e:
        st.error(f"Error: {e}")


# #The "If" check: It filters out empty chunks (sometimes the API sends "empty" packets to keep the connection alive).
# The "Lazy" Loop: It tells Python: "Don't try to loop through response_stream yet. Just wait until st.write_stream asks for a piece of text."
# The Handshake: st.write_stream asks, "Give me the next piece." The generator then grabs exactly one chunk from Groq, hands it over, and then "pauses" its internal state.

# "What if I used square brackets [ ] instead of parentheses ( )?"
# "If you used square brackets, it would create a List. The app would freeze for several seconds because it would wait for the entire AI response to be finished and stored in memory before showing anything on the screen. The 'typewriter' effect would be lost."